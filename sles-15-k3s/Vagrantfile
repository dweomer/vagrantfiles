# -*- mode: ruby -*-
# vi: set ft=ruby :

#
# SELinux is enabled as per the docs at https://documentation.suse.com/sles/15-SP3/html/SLES-all/cha-selinux.html
#
# QUICK START:
# 1. Download SLES 15sp3 vagrant box from https://www.suse.com/download/sles/
# 2. Add the box to your vagrant installation:
#    vagrant box add --name sles15sp3 ~/Downloads/SLES15-SP3-Vagrant.x86_64-15.3-libvirt-PublicRC.vagrant.libvirt.box
# 3. SLES_REGCODE=<sles regcode> MICRO_REGCODE=<microos regcode> vagrant up
#
PREFIX  = ENV.fetch('PREFIX',  ENV.fetch('PFX', ENV.fetch('X',"sles")))  # node name prefix
SERVERS = ENV.fetch('SERVERS', ENV.fetch('SRV', ENV.fetch('S',"1"))).to_i       # number of server nodes
WORKERS = ENV.fetch('WORKERS', ENV.fetch('WKR', ENV.fetch('W',"2"))).to_i       # number of agent nodes

K3S_SELINUX = (!['0', 'false'].include?(ENV['K3S_SELINUX'])).to_s               # enable selinux by default
K3S_TOKEN   = ENV['K3S_TOKEN'] || "sles15sp3"                                   # shared secret for joining
DOCKER      = ['1', 'true'].include?(ENV['DOCKER']).to_s                        # install and enable docker cri?

ENV['K3S_SELINUX'] = K3S_SELINUX
ENV['K3S_TOKEN']   = K3S_TOKEN
ENV['DOCKER']      = DOCKER

Vagrant.configure("2") do |config|
  config.vagrant.plugins = ["vagrant-timezone", "vagrant-reload"]
  config.vagrant.sensitive = [ENV["SLES_REGCODE"], ENV["MICRO_REGCODE"]]

  config.timezone.value = :host

  config.vm.box = "sles15sp3"

  ["libvirt", "virtualbox"].each do |p|
    config.vm.provider p do |v, o|
      v.memory = "2048"
      v.cpus = 2
    end
  end

  config.vm.synced_folder '.', '/vagrant', disabled: true

  SERVERS.times do |i|
    config.vm.define "srv-#{i+1}", primary: i==0 do |node|
      node.vm.hostname = "#{PREFIX}-srv-#{i+1}"
      node.vm.provision "install-k3s", type: "shell", run: "once" do |sh|
        sh.upload_path = "/tmp/vagrant-install-k3s"
        # inject provision-time environment variables
        sh.env = ENV.select{|k,v| k.start_with?('K3S_') || k.start_with?('INSTALL_K3S_')}.merge({
            :INSTALL_K3S_EXEC => "server",
            :INSTALL_K3S_NAME => "server",
            :INSTALL_K3S_SKIP_SELINUX_RPM => "true",
            :INSTALL_K3S_SKIP_START => "true",
            :K3S_KUBECONFIG_MODE => "0644",
        })
        if i == 0 then
            sh.env['K3S_CLUSTER_INIT'] = "true"                     # the first server is special
        else
            sh.env['K3S_URL'] = "https://#{PREFIX}-srv-1:6443"      # the remaining servers are not
        end
        # 1. setup k3s config file
        # 2. augment unit with an exec-start-pre restorecon to guard against naive updates
        # 3. install k3s
        # 4. enable the unit
        sh.inline = <<~SHELL
            #!/usr/bin/env bash
            set -eux -o pipefail
            mkdir -vp /etc/rancher/k3s
            cat << CONF > /etc/rancher/k3s/config.yaml
docker: #{DOCKER}
CONF
            mkdir -vp /etc/systemd/system/k3s-${INSTALL_K3S_NAME}.service.d
            cat << UNIT > /etc/systemd/system/k3s-${INSTALL_K3S_NAME}.service.d/restorecon.conf
[Service]
ExecStartPre=-/sbin/restorecon /usr/local/bin/k3s
UNIT
            curl -fsSL https://get.k3s.io | sh
            chmod +x /usr/local/bin/k3s
            systemctl enable --now k3s-${INSTALL_K3S_NAME} || true
        SHELL
      end
    end
  end

  WORKERS.times do |i|
    config.vm.define "wkr-#{i+1}" do |node|
      node.vm.hostname = "#{PREFIX}-wkr-#{i+1}"
      node.vm.provision "install-k3s", type: "shell", run: "once" do |sh|
        sh.upload_path = "/tmp/vagrant-install-k3s"
        # inject provision-time environment variables
        sh.env = ENV.select{|k,v| k.start_with?('K3S_') || k.start_with?('INSTALL_K3S_')}.merge({
            :INSTALL_K3S_EXEC => "agent",
            :INSTALL_K3S_NAME => "agent",
            :INSTALL_K3S_SKIP_SELINUX_RPM => "true",
            :INSTALL_K3S_SKIP_START => "true",
            :K3S_URL => "https://#{PREFIX}-srv-1:6443",
        })
        # 1. setup k3s config file
        # 2. augment unit with an exec-start-pre restorecon to guard against naive updates
        # 3. install k3s
        # 4. enable the unit
        sh.inline = <<~SHELL
            #!/usr/bin/env bash
            set -eux -o pipefail
            mkdir -vp /etc/rancher/k3s
            cat << CONF > /etc/rancher/k3s/config.yaml
docker: #{DOCKER}
CONF
            mkdir -vp /etc/systemd/system/k3s-${INSTALL_K3S_NAME}.service.d
            cat << UNIT > /etc/systemd/system/k3s-${INSTALL_K3S_NAME}.service.d/restorecon.conf
[Service]
ExecStartPre=-/sbin/restorecon /usr/local/bin/k3s
UNIT
            curl -fsSL https://get.k3s.io | sh
            chmod +x /usr/local/bin/k3s
            systemctl enable --now k3s-${INSTALL_K3S_NAME} || true
        SHELL
      end
    end
  end

  config.vm.provision "register", type: "shell", run: "once" do |sh|
    sh.upload_path = "/tmp/vagrant-register"
    sh.env = {
        'SLES_REGCODE': ENV['SLES_REGCODE'],
        'MICRO_REGCODE': ENV['MICRO_REGCODE'],
        'MICRO_PRODUCT': ENV['MICRO_PRODUCT'] || "SUSE-MicroOS/5.1/x86_64",
    }
    sh.inline = <<~SHELL
        #!/usr/bin/env bash
        set -eux -o pipefail
        SUSEConnect -r "${SLES_REGCODE}"
        SUSEConnect -r "${MICRO_REGCODE}" -p "${MICRO_PRODUCT}" || true
    SHELL
  end

  # To re-run, installing CNI from RPM:
  #   PACKAGES="containernetworking-plugins" vagrant up --provision-with=packages
  #
  config.vm.provision "packages", type: "shell", run: "once" do |sh|
    sh.upload_path = "/tmp/vagrant-packages"
    sh.env = {
        'PACKAGES': ENV['PACKAGES'] || "https://github.com/k3s-io/k3s-selinux/releases/download/v0.5.testing.2/container-selinux-2.164.3-0.noarch.rpm https://github.com/k3s-io/k3s-selinux/releases/download/v0.5.testing.2/k3s-selinux-0.5-2.sle.noarch.rpm",
        'MICRO_REPO': ENV['MICRO_REPO'] || "SUSE-MicroOS-5.1-Pool",
    }
    sh.inline = <<~SHELL
        #!/usr/bin/env bash
        set -eux -o pipefail
        rpm --import https://rpm-testing.rancher.io/public.key
        rpm --import https://rpm.rancher.io/public.key
        zypper update --repo ${MICRO_REPO} --no-confirm
        zypper install --repo ${MICRO_REPO} --no-confirm --allow-unsigned-rpm \
            audit \
            bash \
            curl \
            iptables \
            less \
            lsof \
            patterns-microos-selinux \
            policycoreutils-python-utils \
            systemd \
            ${PACKAGES}
    SHELL
  end

  # configure kernel command-line then reboot
  config.vm.provision "sles-selinux-grub", type: "shell", run: "once" do |sh|
    sh.upload_path = "/tmp/vagrant-sles-selinux-grub"
    sh.inline = <<~SHELL
        #!/usr/bin/env bash
        set -eux -o pipefail
        sed -r 's/(GRUB_CMDLINE_LINUX_DEFAULT)[=]["](.*)["]/\\1="\\2 security=selinux selinux=1"/g' -i.orig /etc/default/grub
        grub2-mkconfig -o /boot/grub2/grub.cfg
    SHELL
  end
  config.vm.provision "sles-selinux-grub-reboot", type: "reload", run: "once"

  # label the entire filesystem then reboot
  config.vm.provision "sles-selinux-restorecon", type: "shell", run: "once" do |sh|
    sh.upload_path = "/tmp/vagrant-sles-selinux-restorecon"
    sh.inline = <<~SHELL
        #!/usr/bin/env bash
        set -eux -o pipefail
        restorecon -R /
        sestatus -v
        truncate /var/log/audit/audit.log --reference /dev/null
        sed -e 's/SELINUX=.*/SELINUX=enforcing/g' -i.orig /etc/selinux/config
    SHELL
  end
  config.vm.provision "sles-selinux-restorecon-reboot", type: "reload", run: "once"

  # SELinux is Enforcing by default.
  # To set SELinux as Disabled on a VM that has already been provisioned:
  #   SELINUX=Disabled vagrant up --provision-with=selinux
  # To set SELinux as Permissive on a VM that has already been provsioned
  #   SELINUX=Permissive vagrant up --provision-with=selinux
  config.vm.provision "selinux", type: "shell", run: "once" do |sh|
    sh.upload_path = "/tmp/vagrant-selinux"
    sh.env = {
        'SELINUX': ENV['SELINUX'] || "Enforcing"
    }
    sh.inline = <<~SHELL
        #!/usr/bin/env bash
        set -eux -o pipefail

        if ! type -p getenforce setenforce &>/dev/null; then
          echo SELinux is Unsupported
          exit 0
        fi

        case "${SELINUX}" in
          Disabled)
            if mountpoint -q /sys/fs/selinux; then
              setenforce 0
              umount -v /sys/fs/selinux
            fi
            ;;
          Enforcing)
            mountpoint -q /sys/fs/selinux || mount -o rw,relatime -t selinuxfs selinuxfs /sys/fs/selinux
            setenforce 1
            ;;
          Permissive)
            mountpoint -q /sys/fs/selinux || mount -o rw,relatime -t selinuxfs selinuxfs /sys/fs/selinux
            setenforce 0
            ;;
          *)
            echo "SELinux mode not supported: ${SELINUX}" >&2
            exit 1
            ;;
        esac
        sestatus -v
    SHELL
  end

  config.vm.provision "install-docker", type: "shell", run: (DOCKER == "true" ? "once" : "never") do |sh|
    sh.upload_path = "/tmp/vagrant-install-docker"
    sh.inline = <<~SHELL
        #!/usr/bin/env bash
        set -eux -o pipefail
        zypper install -y \
            docker
        mkdir -vp /etc/docker
        cat <<-EOF >/etc/docker/daemon.json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "selinux-enabled": #{K3S_SELINUX}
}
EOF
        mkdir -vp /usr/lib/systemd/system/docker.service.d
        cat <<-EOF > /usr/lib/systemd/system/docker.service.d/00-local.conf
[Service]
ExecStartPre=-/sbin/modprobe br_netfilter
ExecStartPre=-/sbin/sysctl -w net.bridge.bridge-nf-call-iptables=1
ExecStartPre=-/sbin/sysctl -w net.bridge.bridge-nf-call-ip6tables=1
ExecStartPre=-/sbin/sysctl -w net.ipv4.conf.all.forwarding=1
ExecStartPre=-/sbin/sysctl -w net.ipv6.conf.all.forwarding=1
EOF
        systemctl enable --now docker
    SHELL
  end

  config.vm.provision "install-suc", type: "shell", run: "never" do |sh|
    sh.upload_path = "/tmp/vagrant-install-suc"
    sh.env = {
        'SUC_MANIFEST_URL': ENV['SUC_MANIFEST_URL'] || "https://github.com/rancher/system-upgrade-controller/releases/download/v0.7.5/system-upgrade-controller.yaml",
    }
    sh.inline = <<~SHELL
        #!/usr/bin/env bash
        set -eux -o pipefail
        while ! /usr/local/bin/kubectl get node &>/dev/null; do
            sleep 5
        done
        curl -fsSL ${SUC_MANIFEST_URL} | /usr/local/bin/kubectl apply -f-
    SHELL
  end

  config.vm.provision "install-suc-plans", type: "shell", run: "never" do |sh|
    sh.upload_path = "/tmp/vagrant-install-suc-plans"
    sh.env = {
        'UPGRADE_K3S_VERSION': ENV['UPGRADE_K3S_VERSION'],
    }
    sh.inline = <<~SHELL
        #!/usr/bin/env bash
        set -eux -o pipefail
        while ! /usr/local/bin/kubectl get node &>/dev/null; do
            sleep 5
        done
        cat << EOF > k3s-upgrade.yaml
---
apiVersion: upgrade.cattle.io/v1
kind: Plan
metadata:
  name: k3s-server
  namespace: system-upgrade
  labels:
    k3s-upgrade: server
spec:
  concurrency: 1
  version: ${UPGRADE_K3S_VERSION}
  nodeSelector:
    matchExpressions:
      - {key: k3s.io/upgrade, operator: In, values: ["true", "enabled"]}
      - {key: node-role.kubernetes.io/master, operator: Exists}
  serviceAccountName: system-upgrade
  cordon: true
  upgrade:
    image: rancher/k3s-upgrade
---
apiVersion: upgrade.cattle.io/v1
kind: Plan
metadata:
  name: k3s-agent
  namespace: system-upgrade
  labels:
    k3s-upgrade: agent
spec:
  concurrency: 2
  version: ${UPGRADE_K3S_VERSION}
  nodeSelector:
    matchExpressions:
      - {key: k3s.io/upgrade, operator: In, values: ["true", "enabled"]}
      - {key: node-role.kubernetes.io/master, operator: DoesNotExist}
  serviceAccountName: system-upgrade
  prepare:
    image: rancher/k3s-upgrade
    args: ["prepare", "k3s-server"]
  drain:
    force: true
    skipWaitForDeleteTimeout: 30
  upgrade:
    image: rancher/k3s-upgrade
EOF
        while ! /usr/local/bin/kubectl apply -f k3s-upgrade.yaml; do
            sleep 5
        done
    SHELL
  end

  config.vm.provision "upgrade-cluster", type: "shell", run: "never" do |sh|
    sh.upload_path = "/tmp/vagrant-upgrade-cluster"
    sh.inline = <<~SHELL
        #!/usr/bin/env bash
        set -eux -o pipefail
        while ! /usr/local/bin/kubectl get node &>/dev/null; do
            sleep 5
        done
        /usr/local/bin/kubectl label node --all k3s.io/upgrade=enabled --overwrite=true
    SHELL
  end

end
